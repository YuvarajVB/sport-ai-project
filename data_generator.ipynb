{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c15746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
    "                             f1_score, cohen_kappa_score)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2563187",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"[INFO] XGBoost not installed. Run: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"[INFO] SHAP not installed. Run: pip install shap\")\n",
    "\n",
    "try:\n",
    "    import joblib\n",
    "    JOBLIB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    import pickle\n",
    "    JOBLIB_AVAILABLE = False\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc731aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(n_samples=200000):\n",
    "    \"\"\"\n",
    "    Generate realistic synthetic dataset with 200,000 samples.\n",
    "    FIX 1: Sport profiles are now physiologically DISTINCT to improve separability.\n",
    "    FIX 3: Age and Gender added as features.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    sports = ['Football', 'Volleyball', 'Swimming', 'Basketball', 'Athletics', 'Gymnastics']\n",
    "\n",
    "    # =========================================================================\n",
    "    # FIX 1 - DISTINCT SPORT PROFILES (changed from original overlapping ranges)\n",
    "    # Key distinctors:\n",
    "    #   Basketball  → VERY TALL (172-195 cm)\n",
    "    #   Volleyball  → TALL (165-190 cm)\n",
    "    #   Gymnastics  → SHORT + LIGHTEST (130-158 cm, 28-50 kg) + HIGHEST flexibility\n",
    "    #   Athletics   → VERY LEAN (38-58 kg) + HIGHEST gait/walking\n",
    "    #   Swimming    → HIGHEST flexibility (78-98) + LOW gait\n",
    "    #   Football    → HIGH strength (72-95) + HIGH gait\n",
    "    # =========================================================================\n",
    "    sport_profiles = {\n",
    "        'Football': {\n",
    "            'height_range':      (148, 170),   # Medium height\n",
    "            'weight_range':      (45, 68),\n",
    "            'strength_range':    (72, 95),     # HIGH strength ← distinct\n",
    "            'flexibility_range': (45, 65),     # LOW flexibility ← distinct\n",
    "            'gait_range':        (75, 95),     # HIGH gait ← distinct\n",
    "            'walking_range':     (70, 90),\n",
    "            'gender_bias':       0.75,         # 75% male in school football\n",
    "        },\n",
    "        'Volleyball': {\n",
    "            'height_range':      (165, 190),   # TALL ← distinct\n",
    "            'weight_range':      (55, 78),\n",
    "            'strength_range':    (55, 78),\n",
    "            'flexibility_range': (65, 85),\n",
    "            'gait_range':        (60, 80),\n",
    "            'walking_range':     (58, 78),\n",
    "            'gender_bias':       0.50,\n",
    "        },\n",
    "        'Swimming': {\n",
    "            'height_range':      (155, 182),\n",
    "            'weight_range':      (42, 63),     # LEAN\n",
    "            'strength_range':    (50, 75),\n",
    "            'flexibility_range': (78, 98),     # VERY HIGH flexibility ← distinct\n",
    "            'gait_range':        (50, 70),     # LOW gait ← distinct\n",
    "            'walking_range':     (48, 68),\n",
    "            'gender_bias':       0.50,\n",
    "        },\n",
    "        'Basketball': {\n",
    "            'height_range':      (172, 195),   # VERY TALL ← distinct\n",
    "            'weight_range':      (60, 85),\n",
    "            'strength_range':    (65, 88),\n",
    "            'flexibility_range': (52, 72),\n",
    "            'gait_range':        (78, 96),     # HIGH gait\n",
    "            'walking_range':     (75, 92),\n",
    "            'gender_bias':       0.60,\n",
    "        },\n",
    "        'Athletics': {\n",
    "            'height_range':      (150, 175),\n",
    "            'weight_range':      (38, 58),     # VERY LEAN ← distinct\n",
    "            'strength_range':    (70, 95),     # HIGH strength\n",
    "            'flexibility_range': (62, 82),\n",
    "            'gait_range':        (85, 100),    # HIGHEST gait ← distinct\n",
    "            'walking_range':     (82, 100),    # HIGHEST walking ← distinct\n",
    "            'gender_bias':       0.50,\n",
    "        },\n",
    "        'Gymnastics': {\n",
    "            'height_range':      (130, 158),   # SHORT ← distinct\n",
    "            'weight_range':      (28, 50),     # LIGHTEST ← distinct\n",
    "            'strength_range':    (65, 90),\n",
    "            'flexibility_range': (85, 100),    # HIGHEST flexibility ← distinct\n",
    "            'gait_range':        (68, 88),\n",
    "            'walking_range':     (65, 85),\n",
    "            'gender_bias':       0.20,         # 80% female in school gymnastics\n",
    "        },\n",
    "    }\n",
    "\n",
    "    samples_per_sport = n_samples // len(sports)\n",
    "\n",
    "    for sport in sports:\n",
    "        profile = sport_profiles[sport]\n",
    "        for _ in range(samples_per_sport):\n",
    "\n",
    "            # FIX 2 - TIGHTER NOISE (reduced from ±3/5/4 to ±1.5/2.5/2.0)\n",
    "            # Less noise = cleaner class boundaries = higher accuracy\n",
    "            height       = np.random.uniform(*profile['height_range'])      + np.random.normal(0, 1.5)\n",
    "            weight       = np.random.uniform(*profile['weight_range'])       + np.random.normal(0, 1.5)\n",
    "            bmi          = weight / ((height / 100) ** 2)\n",
    "            strength     = np.random.uniform(*profile['strength_range'])     + np.random.normal(0, 2.5)\n",
    "            flexibility  = np.random.uniform(*profile['flexibility_range'])  + np.random.normal(0, 2.0)\n",
    "            gait         = np.random.uniform(*profile['gait_range'])         + np.random.normal(0, 2.0)\n",
    "            walking_score= np.random.uniform(*profile['walking_range'])      + np.random.normal(0, 1.5)\n",
    "\n",
    "            # Clip to realistic ranges\n",
    "            height        = np.clip(height,        130, 200)\n",
    "            weight        = np.clip(weight,         28,  90)\n",
    "            bmi           = np.clip(bmi,            14,  32)\n",
    "            strength      = np.clip(strength,       20, 100)\n",
    "            flexibility   = np.clip(flexibility,    20, 100)\n",
    "            gait          = np.clip(gait,           30, 100)\n",
    "            walking_score = np.clip(walking_score,  30, 100)\n",
    "\n",
    "            # FIX 3 - AGE AND GENDER (new features)\n",
    "            age    = np.random.randint(11, 15)   # 6th-8th standard = age 11-14\n",
    "            gender = 1 if np.random.random() < profile['gender_bias'] else 0  # 1=Male, 0=Female\n",
    "\n",
    "            data.append({\n",
    "                'height_cm':          round(height,        1),\n",
    "                'weight_kg':          round(weight,        1),\n",
    "                'bmi':                round(bmi,           2),\n",
    "                'strength_score':     round(strength,      1),\n",
    "                'flexibility_score':  round(flexibility,   1),\n",
    "                'gait_score':         round(gait,          1),\n",
    "                'walking_score':      round(walking_score, 1),\n",
    "                'age':                age,          # FIX 3 - NEW\n",
    "                'gender':             gender,       # FIX 3 - NEW (1=Male, 0=Female)\n",
    "                'sport_label':        sport\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55ca45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Add domain-relevant composite features.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df['athleticism_index'] = (\n",
    "        df['strength_score']    * 0.3 +\n",
    "        df['flexibility_score'] * 0.2 +\n",
    "        df['gait_score']        * 0.25 +\n",
    "        df['walking_score']     * 0.25\n",
    "    )\n",
    "    df['power_to_weight']     = df['strength_score'] / df['weight_kg']\n",
    "    df['mobility_score']      = (df['gait_score'] + df['walking_score'] + df['flexibility_score']) / 3\n",
    "    df['height_weight_ratio'] = df['height_cm'] / df['weight_kg']\n",
    "    df['bmi_category']        = pd.cut(df['bmi'],\n",
    "                                        bins=[0, 18.5, 23, 27.5, 100],\n",
    "                                        labels=[0, 1, 2, 3]).astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c17a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Encode labels, scale features, and split data.\"\"\"\n",
    "    df = engineer_features(df)\n",
    "\n",
    "    # FIX 3 - 'age' and 'gender' added to feature list\n",
    "    feature_cols = [\n",
    "        'height_cm', 'weight_kg', 'bmi', 'strength_score', 'flexibility_score',\n",
    "        'gait_score', 'walking_score', 'age', 'gender',\n",
    "        'athleticism_index', 'power_to_weight',\n",
    "        'mobility_score', 'height_weight_ratio', 'bmi_category'\n",
    "    ]\n",
    "\n",
    "    X = df[feature_cols]\n",
    "    y = df['sport_label']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, label_encoder, feature_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be811acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. MODEL BUILDING\n",
    "# =============================================================================\n",
    "\n",
    "def build_models():\n",
    "    \"\"\"Define all candidate models.\"\"\"\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features='sqrt',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'SGD Classifier': CalibratedClassifierCV(\n",
    "            SGDClassifier(\n",
    "                loss='modified_huber',\n",
    "                max_iter=1000,\n",
    "                tol=1e-3,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            cv=3\n",
    "        ),\n",
    "        'Neural Network': MLPClassifier(\n",
    "            hidden_layer_sizes=(256, 128, 64),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=500,\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        models['XGBoost'] = xgb.XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e598092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. ENSEMBLE MODEL\n",
    "# =============================================================================\n",
    "\n",
    "def build_ensemble(X_train, y_train):\n",
    "    \"\"\"Voting Ensemble: RF + GB + SGD.\"\"\"\n",
    "    rf  = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "    gb  = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "    sgd = CalibratedClassifierCV(\n",
    "        SGDClassifier(loss='modified_huber', max_iter=1000, random_state=42, n_jobs=-1),\n",
    "        cv=3\n",
    "    )\n",
    "\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb), ('sgd', sgd)],\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    return ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d040c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_random_forest(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators':     [200, 300, 500],\n",
    "        'max_depth':        [None, 10, 20],\n",
    "        'min_samples_split':[2, 5],\n",
    "        'max_features':     ['sqrt', 'log2'],\n",
    "    }\n",
    "    rf  = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    cv  = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    gs  = GridSearchCV(rf, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(f\"\\nBest RF Parameters: {gs.best_params_}\")\n",
    "    print(f\"Best CV Score     : {gs.best_score_:.4f}\")\n",
    "    return gs.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bec9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, label_encoder, model_name=\"Model\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc    = accuracy_score(y_test, y_pred)\n",
    "    f1     = f1_score(y_test, y_pred, average='macro')\n",
    "    kappa  = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {model_name} - Evaluation Results\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Accuracy        : {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"  F1 Score (Macro): {f1:.4f}\")\n",
    "    print(f\"  Cohen's Kappa   : {kappa:.4f}\")\n",
    "    print(f\"\\n  Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    return acc, f1, kappa, y_pred\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, label_encoder, model_name):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('Actual Sport')\n",
    "    plt.xlabel('Predicted Sport')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'confusion_matrix_{model_name.replace(\" \", \"_\")}.png', dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  Confusion matrix saved.\")\n",
    "\n",
    "\n",
    "def plot_feature_importance(model, feature_cols):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        fi_df = pd.DataFrame({'Feature': feature_cols, 'Importance': importances})\n",
    "        fi_df = fi_df.sort_values('Importance', ascending=True)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.barh(fi_df['Feature'], fi_df['Importance'], color='steelblue')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Feature Importances - Random Forest')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png', dpi=150)\n",
    "        plt.close()\n",
    "        print(\"  Feature importance chart saved.\")\n",
    "\n",
    "\n",
    "def compare_models(results_dict):\n",
    "    names      = list(results_dict.keys())\n",
    "    accuracies = [results_dict[n]['accuracy'] for n in names]\n",
    "    f1s        = [results_dict[n]['f1']       for n in names]\n",
    "\n",
    "    x     = np.arange(len(names))\n",
    "    width = 0.35\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, accuracies, width, label='Accuracy',         color='steelblue')\n",
    "    bars2 = ax.bar(x + width/2, f1s,        width, label='F1 Score (Macro)', color='darkorange')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Comparison - Accuracy & F1 Score')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(names, rotation=15, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.bar_label(bars1, fmt='%.3f', padding=3)\n",
    "    ax.bar_label(bars2, fmt='%.3f', padding=3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=150)\n",
    "    plt.close()\n",
    "    print(\"  Model comparison chart saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49539f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. PREDICTION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def predict_sport(model, scaler, label_encoder, student_data: dict):\n",
    "    \"\"\"\n",
    "    Predict sport for a single student.\n",
    "    student_data keys: height_cm, weight_kg, bmi, strength_score,\n",
    "                       flexibility_score, gait_score, walking_score,\n",
    "                       age, gender  ← FIX 3: age & gender now required\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([student_data])\n",
    "    df = engineer_features(df)\n",
    "\n",
    "    feature_cols = [\n",
    "        'height_cm', 'weight_kg', 'bmi', 'strength_score', 'flexibility_score',\n",
    "        'gait_score', 'walking_score', 'age', 'gender',\n",
    "        'athleticism_index', 'power_to_weight',\n",
    "        'mobility_score', 'height_weight_ratio', 'bmi_category'\n",
    "    ]\n",
    "\n",
    "    X            = scaler.transform(df[feature_cols])\n",
    "    pred_encoded = model.predict(X)[0]\n",
    "    pred_proba   = model.predict_proba(X)[0]\n",
    "    sport        = label_encoder.inverse_transform([pred_encoded])[0]\n",
    "\n",
    "    top3_idx    = np.argsort(pred_proba)[::-1][:3]\n",
    "    top3_sports = label_encoder.inverse_transform(top3_idx)\n",
    "    top3_proba  = pred_proba[top3_idx]\n",
    "\n",
    "    return {\n",
    "        'primary_recommendation': sport,\n",
    "        'confidence': f\"{pred_proba[pred_encoded]*100:.1f}%\",\n",
    "        'top_3_recommendations': [\n",
    "            {'sport': s, 'probability': f\"{p*100:.1f}%\"}\n",
    "            for s, p in zip(top3_sports, top3_proba)\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e254b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. SAVE / LOAD MODEL\n",
    "# =============================================================================\n",
    "\n",
    "def save_model(model, scaler, label_encoder, filename='sport_prediction_model'):\n",
    "    if JOBLIB_AVAILABLE:\n",
    "        joblib.dump({'model': model, 'scaler': scaler, 'label_encoder': label_encoder},\n",
    "                    f'{filename}.joblib')\n",
    "        print(f\"  Model saved as: {filename}.joblib\")\n",
    "    else:\n",
    "        with open(f'{filename}.pkl', 'wb') as f:\n",
    "            pickle.dump({'model': model, 'scaler': scaler, 'label_encoder': label_encoder}, f)\n",
    "        print(f\"  Model saved as: {filename}.pkl\")\n",
    "\n",
    "\n",
    "def load_model(filename='sport_prediction_model'):\n",
    "    if JOBLIB_AVAILABLE:\n",
    "        data = joblib.load(f'{filename}.joblib')\n",
    "    else:\n",
    "        with open(f'{filename}.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "    return data['model'], data['scaler'], data['label_encoder']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 10. CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "def cross_validate_model(model, X_train, y_train, model_name):\n",
    "    cv       = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores= cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"\\n  {model_name} - 5-Fold CV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    return cv_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7c3943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  SPORT SUITABILITY PREDICTION SYSTEM\n",
      "  Multi-Class ML Model for School Children\n",
      "  Fixes Applied: Distinct Profiles + Tighter Noise + Age/Gender\n",
      "============================================================\n",
      "\n",
      "[1] Generating training dataset (200,000 samples)...\n",
      "    Dataset shape: (199998, 10)\n",
      "    Sport distribution:\n",
      "sport_label\n",
      "Athletics     33333\n",
      "Basketball    33333\n",
      "Volleyball    33333\n",
      "Football      33333\n",
      "Gymnastics    33333\n",
      "Swimming      33333\n",
      "\n",
      "[2] Preprocessing data & engineering features...\n",
      "    Train size   : 159998\n",
      "    Test size    : 40000\n",
      "    Feature count: 14\n",
      "\n",
      "[3] Training individual models...\n",
      "\n",
      "    Training: Random Forest...\n",
      "\n",
      "============================================================\n",
      "  Random Forest - Evaluation Results\n",
      "============================================================\n",
      "  Accuracy        : 0.9861 (98.61%)\n",
      "  F1 Score (Macro): 0.9861\n",
      "  Cohen's Kappa   : 0.9834\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Athletics       0.98      0.98      0.98      6666\n",
      "  Basketball       0.99      0.99      0.99      6666\n",
      "    Football       0.98      0.97      0.98      6667\n",
      "  Gymnastics       1.00      1.00      1.00      6667\n",
      "    Swimming       0.99      0.99      0.99      6667\n",
      "  Volleyball       0.98      0.98      0.98      6667\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "\n",
      "  Random Forest - 5-Fold CV Accuracy: 0.9863 ± 0.0006\n",
      "  Confusion matrix saved.\n",
      "\n",
      "    Training: Gradient Boosting...\n",
      "\n",
      "============================================================\n",
      "  Gradient Boosting - Evaluation Results\n",
      "============================================================\n",
      "  Accuracy        : 0.9855 (98.55%)\n",
      "  F1 Score (Macro): 0.9855\n",
      "  Cohen's Kappa   : 0.9826\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Athletics       0.98      0.98      0.98      6666\n",
      "  Basketball       0.99      0.99      0.99      6666\n",
      "    Football       0.98      0.98      0.98      6667\n",
      "  Gymnastics       1.00      1.00      1.00      6667\n",
      "    Swimming       0.98      0.98      0.98      6667\n",
      "  Volleyball       0.98      0.98      0.98      6667\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "\n",
      "  Gradient Boosting - 5-Fold CV Accuracy: 0.9860 ± 0.0005\n",
      "  Confusion matrix saved.\n",
      "\n",
      "    Training: SGD Classifier...\n",
      "\n",
      "============================================================\n",
      "  SGD Classifier - Evaluation Results\n",
      "============================================================\n",
      "  Accuracy        : 0.9704 (97.04%)\n",
      "  F1 Score (Macro): 0.9704\n",
      "  Cohen's Kappa   : 0.9645\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Athletics       0.97      0.97      0.97      6666\n",
      "  Basketball       0.97      0.98      0.98      6666\n",
      "    Football       0.95      0.96      0.96      6667\n",
      "  Gymnastics       1.00      0.99      1.00      6667\n",
      "    Swimming       0.97      0.98      0.97      6667\n",
      "  Volleyball       0.96      0.95      0.95      6667\n",
      "\n",
      "    accuracy                           0.97     40000\n",
      "   macro avg       0.97      0.97      0.97     40000\n",
      "weighted avg       0.97      0.97      0.97     40000\n",
      "\n",
      "\n",
      "  SGD Classifier - 5-Fold CV Accuracy: 0.9708 ± 0.0010\n",
      "  Confusion matrix saved.\n",
      "\n",
      "    Training: Neural Network...\n",
      "\n",
      "============================================================\n",
      "  Neural Network - Evaluation Results\n",
      "============================================================\n",
      "  Accuracy        : 0.9858 (98.58%)\n",
      "  F1 Score (Macro): 0.9858\n",
      "  Cohen's Kappa   : 0.9830\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Athletics       0.98      0.98      0.98      6666\n",
      "  Basketball       0.99      0.99      0.99      6666\n",
      "    Football       0.98      0.98      0.98      6667\n",
      "  Gymnastics       1.00      1.00      1.00      6667\n",
      "    Swimming       0.98      0.99      0.98      6667\n",
      "  Volleyball       0.98      0.98      0.98      6667\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "\n",
      "  Neural Network - 5-Fold CV Accuracy: 0.9853 ± 0.0008\n",
      "  Confusion matrix saved.\n",
      "\n",
      "    Training: XGBoost...\n",
      "\n",
      "============================================================\n",
      "  XGBoost - Evaluation Results\n",
      "============================================================\n",
      "  Accuracy        : 0.9860 (98.60%)\n",
      "  F1 Score (Macro): 0.9860\n",
      "  Cohen's Kappa   : 0.9832\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Athletics       0.98      0.98      0.98      6666\n",
      "  Basketball       0.99      0.99      0.99      6666\n",
      "    Football       0.98      0.98      0.98      6667\n",
      "  Gymnastics       1.00      1.00      1.00      6667\n",
      "    Swimming       0.98      0.98      0.98      6667\n",
      "  Volleyball       0.98      0.98      0.98      6667\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "\n",
      "  XGBoost - 5-Fold CV Accuracy: 0.9860 ± 0.0004\n",
      "  Confusion matrix saved.\n",
      "\n",
      "[4] Building Ensemble Model (Recommended)...\n",
      "\n",
      "============================================================\n",
      "  Ensemble - Evaluation Results\n",
      "============================================================\n",
      "  Accuracy        : 0.9862 (98.62%)\n",
      "  F1 Score (Macro): 0.9862\n",
      "  Cohen's Kappa   : 0.9835\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Athletics       0.98      0.98      0.98      6666\n",
      "  Basketball       0.99      0.99      0.99      6666\n",
      "    Football       0.98      0.98      0.98      6667\n",
      "  Gymnastics       1.00      1.00      1.00      6667\n",
      "    Swimming       0.98      0.99      0.98      6667\n",
      "  Volleyball       0.98      0.98      0.98      6667\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "  Confusion matrix saved.\n",
      "\n",
      "[5] Generating feature importance...\n",
      "  Feature importance chart saved.\n",
      "\n",
      "[6] Comparing all models...\n",
      "  Model comparison chart saved.\n",
      "\n",
      "[7] Best Model: Ensemble\n",
      "    Accuracy   : 98.62%\n",
      "\n",
      "[8] Saving trained model...\n",
      "  Model saved as: sport_prediction_model.joblib\n",
      "\n",
      "[9] Example Student Prediction:\n",
      "\n",
      "    Student Data : {'height_cm': 162.0, 'weight_kg': 55.0, 'bmi': 20.97, 'strength_score': 78.0, 'flexibility_score': 82.0, 'gait_score': 75.0, 'walking_score': 73.0, 'age': 13, 'gender': 1}\n",
      "\n",
      "    PRIMARY RECOMMENDATION : Volleyball\n",
      "    Confidence             : 63.3%\n",
      "\n",
      "    Top 3 Recommendations:\n",
      "      1. Volleyball - 63.3%\n",
      "      2. Football - 18.5%\n",
      "      3. Swimming - 7.2%\n",
      "\n",
      "============================================================\n",
      "  PIPELINE COMPLETE!\n",
      "  Files generated:\n",
      "    - sport_training_data.csv        (200,000 row dataset)\n",
      "    - sport_prediction_model.joblib  (trained ensemble model)\n",
      "    - confusion_matrix_*.png         (per model)\n",
      "    - feature_importance.png\n",
      "    - model_comparison.png\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 11. MAIN PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  SPORT SUITABILITY PREDICTION SYSTEM\")\n",
    "    print(\"  Multi-Class ML Model for School Children\")\n",
    "    print(\"  Fixes Applied: Distinct Profiles + Tighter Noise + Age/Gender\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Step 1: Generate training data\n",
    "    print(\"\\n[1] Generating training dataset (200,000 samples)...\")\n",
    "    df = generate_training_data(n_samples=200000)\n",
    "    df.to_csv('sport_training_data.csv', index=False)\n",
    "    print(f\"    Dataset shape: {df.shape}\")\n",
    "    print(f\"    Sport distribution:\\n{df['sport_label'].value_counts().to_string()}\")\n",
    "\n",
    "    # Step 2: Preprocess\n",
    "    print(\"\\n[2] Preprocessing data & engineering features...\")\n",
    "    X_train, X_test, y_train, y_test, scaler, label_encoder, feature_cols = preprocess_data(df)\n",
    "    print(f\"    Train size   : {X_train.shape[0]}\")\n",
    "    print(f\"    Test size    : {X_test.shape[0]}\")\n",
    "    print(f\"    Feature count: {len(feature_cols)}\")\n",
    "\n",
    "    # Step 3: Train & evaluate all models\n",
    "    print(\"\\n[3] Training individual models...\")\n",
    "    models  = build_models()\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n    Training: {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        acc, f1, kappa, y_pred = evaluate_model(model, X_test, y_test, label_encoder, name)\n",
    "        cross_validate_model(model, X_train, y_train, name)\n",
    "        plot_confusion_matrix(y_test, y_pred, label_encoder, name)\n",
    "        results[name] = {'accuracy': acc, 'f1': f1, 'kappa': kappa}\n",
    "\n",
    "    # Step 4: Ensemble\n",
    "    print(\"\\n[4] Building Ensemble Model (Recommended)...\")\n",
    "    ensemble = build_ensemble(X_train, y_train)\n",
    "    acc, f1, kappa, y_pred = evaluate_model(ensemble, X_test, y_test, label_encoder, \"Ensemble\")\n",
    "    plot_confusion_matrix(y_test, y_pred, label_encoder, \"Ensemble\")\n",
    "    results['Ensemble'] = {'accuracy': acc, 'f1': f1, 'kappa': kappa}\n",
    "\n",
    "    # Step 5: Feature importance\n",
    "    print(\"\\n[5] Generating feature importance...\")\n",
    "    plot_feature_importance(models['Random Forest'], feature_cols)\n",
    "\n",
    "    # Step 6: Compare\n",
    "    print(\"\\n[6] Comparing all models...\")\n",
    "    compare_models(results)\n",
    "\n",
    "    # Step 7: Best model\n",
    "    best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
    "    print(f\"\\n[7] Best Model: {best_model_name}\")\n",
    "    print(f\"    Accuracy   : {results[best_model_name]['accuracy']*100:.2f}%\")\n",
    "\n",
    "    best_model = ensemble\n",
    "\n",
    "    # Step 8: Save\n",
    "    print(\"\\n[8] Saving trained model...\")\n",
    "    save_model(best_model, scaler, label_encoder)\n",
    "\n",
    "    # Step 9: Example prediction\n",
    "    # FIX 3 - age and gender now included in student data\n",
    "    print(\"\\n[9] Example Student Prediction:\")\n",
    "    example_student = {\n",
    "        'height_cm':          162.0,\n",
    "        'weight_kg':           55.0,\n",
    "        'bmi':                 20.97,\n",
    "        'strength_score':      78.0,\n",
    "        'flexibility_score':   82.0,\n",
    "        'gait_score':          75.0,\n",
    "        'walking_score':       73.0,\n",
    "        'age':                 13,     # FIX 3 - NEW FIELD\n",
    "        'gender':               1,     # FIX 3 - NEW FIELD (1=Male, 0=Female)\n",
    "    }\n",
    "\n",
    "    prediction = predict_sport(best_model, scaler, label_encoder, example_student)\n",
    "    print(f\"\\n    Student Data : {example_student}\")\n",
    "    print(f\"\\n    PRIMARY RECOMMENDATION : {prediction['primary_recommendation']}\")\n",
    "    print(f\"    Confidence             : {prediction['confidence']}\")\n",
    "    print(f\"\\n    Top 3 Recommendations:\")\n",
    "    for i, rec in enumerate(prediction['top_3_recommendations'], 1):\n",
    "        print(f\"      {i}. {rec['sport']} - {rec['probability']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  PIPELINE COMPLETE!\")\n",
    "    print(\"  Files generated:\")\n",
    "    print(\"    - sport_training_data.csv        (200,000 row dataset)\")\n",
    "    print(\"    - sport_prediction_model.joblib  (trained ensemble model)\")\n",
    "    print(\"    - confusion_matrix_*.png         (per model)\")\n",
    "    print(\"    - feature_importance.png\")\n",
    "    print(\"    - model_comparison.png\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return best_model, scaler, label_encoder, results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_model, scaler, label_encoder, results = main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sport (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
